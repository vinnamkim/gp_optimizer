{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn import DQN\n",
    "from torch.nn.functional import smooth_l1_loss\n",
    "from mlnn import MLNN\n",
    "from replay_memory import ReplayMemory, Transition\n",
    "from training import optimize_dqn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 30\n",
    "input_dims = 784\n",
    "hidden_dims = 333\n",
    "output_dims = 10\n",
    "gamma = 0.999\n",
    "target_update = 10\n",
    "len_train_dataset = len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 3\n",
    "n_width = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQN(hidden_dims, hidden_dims, n_width).cuda()\n",
    "target_net = DQN(hidden_dims, hidden_dims, n_width).cuda()\n",
    "model = MLNN(n_layers, n_width, input_dims, hidden_dims, output_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_capacity = 100\n",
    "replay_memory = ReplayMemory(memory_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.get_params())\n",
    "dqn_optimizer = optim.Adam(policy_net.parameters())\n",
    "criterion = CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_dqn(policy_net, target_net, replay_memory, optimizer, batch_size, gamma):\n",
    "    if len(replay_memory) < batch_size:\n",
    "        return\n",
    "    \n",
    "    transitions = replay_memory.sample(batch_size)\n",
    "    \n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    state = torch.stack(batch.state)\n",
    "    action = torch.stack(batch.action).reshape([-1, 1])\n",
    "    next_state = torch.stack(batch.next_state)\n",
    "    reward = torch.stack(batch.reward)\n",
    "    \n",
    "    q_values = policy_net(state).gather(1, action.reshape([-1, 1])).squeeze()\n",
    "    #print(batch.reward)\n",
    "    expected_q_values = (target_net(next_state).max(1)[0].detach() * gamma) + reward\n",
    "\n",
    "    loss = smooth_l1_loss(q_values, expected_q_values)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1.0399, device='cuda:0') tensor(0.0745, device='cuda:0')\n",
      "1 tensor(0.9155, device='cuda:0') tensor(0.0194, device='cuda:0')\n",
      "2 tensor(0.8378, device='cuda:0') tensor(0.0292, device='cuda:0')\n",
      "3 tensor(0.7209, device='cuda:0') tensor(0.0689, device='cuda:0')\n",
      "4 tensor(0.5636, device='cuda:0') tensor(0.1381, device='cuda:0')\n",
      "5 tensor(0.5467, device='cuda:0') tensor(0.1632, device='cuda:0')\n",
      "6 tensor(0.5244, device='cuda:0') tensor(0.1831, device='cuda:0')\n",
      "7 tensor(0.5066, device='cuda:0') tensor(0.1981, device='cuda:0')\n",
      "8 tensor(0.4925, device='cuda:0') tensor(0.2147, device='cuda:0')\n",
      "9 tensor(0.4917, device='cuda:0') tensor(0.2249, device='cuda:0')\n",
      "10 tensor(0.5316, device='cuda:0') tensor(0.1999, device='cuda:0')\n",
      "11 tensor(0.5124, device='cuda:0') tensor(0.2072, device='cuda:0')\n",
      "12 tensor(0.5054, device='cuda:0') tensor(0.2153, device='cuda:0')\n",
      "13 tensor(0.4916, device='cuda:0') tensor(0.2253, device='cuda:0')\n",
      "14 tensor(0.4562, device='cuda:0') tensor(0.2550, device='cuda:0')\n",
      "15 tensor(0.4227, device='cuda:0') tensor(0.2862, device='cuda:0')\n",
      "16 tensor(0.3665, device='cuda:0') tensor(0.3525, device='cuda:0')\n",
      "17 tensor(0.3886, device='cuda:0') tensor(0.3539, device='cuda:0')\n",
      "18 tensor(0.4061, device='cuda:0') tensor(0.3358, device='cuda:0')\n",
      "19 tensor(0.4098, device='cuda:0') tensor(0.3435, device='cuda:0')\n",
      "20 tensor(0.4278, device='cuda:0') tensor(0.3328, device='cuda:0')\n",
      "21 tensor(0.4271, device='cuda:0') tensor(0.3528, device='cuda:0')\n",
      "22 tensor(0.4466, device='cuda:0') tensor(0.3322, device='cuda:0')\n",
      "23 tensor(0.4140, device='cuda:0') tensor(0.3339, device='cuda:0')\n",
      "24 tensor(0.3802, device='cuda:0') tensor(0.3615, device='cuda:0')\n",
      "25 tensor(0.3722, device='cuda:0') tensor(0.3607, device='cuda:0')\n",
      "26 tensor(0.3663, device='cuda:0') tensor(0.3685, device='cuda:0')\n",
      "27 tensor(0.4312, device='cuda:0') tensor(0.3442, device='cuda:0')\n",
      "28 tensor(0.3951, device='cuda:0') tensor(0.3596, device='cuda:0')\n",
      "29 tensor(0.3601, device='cuda:0') tensor(0.3842, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "avg_mlnn_losses = []\n",
    "avg_dqn_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_mlnn_loss = 0.\n",
    "    avg_dqn_loss = 0.\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28 * 28)).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "\n",
    "        replays, loss, outputs = model.train(images, labels, policy_net, criterion)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_mlnn_loss += loss.detach()\n",
    "\n",
    "        for replay in replays:\n",
    "            replay_memory.push(replay.state, replay.action, replay.next_state, replay.reward)\n",
    "\n",
    "        avg_dqn_loss += optimize_dqn(policy_net, target_net, replay_memory, dqn_optimizer, batch_size, gamma)\n",
    "\n",
    "        if i % target_update == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    avg_mlnn_loss /= float(i)\n",
    "    avg_dqn_loss /= float(i)\n",
    "    \n",
    "    avg_mlnn_losses.append(avg_mlnn_loss)\n",
    "    avg_dqn_losses.append(avg_dqn_loss)\n",
    "    \n",
    "    print(epoch, avg_mlnn_loss.data, avg_dqn_loss.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
